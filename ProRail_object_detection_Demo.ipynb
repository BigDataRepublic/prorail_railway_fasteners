{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProRail_object_detection_Demo.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPGWBopcoZA2gjfihB64Y9D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vantage-AI/prorail_railway_fasteners/blob/master/ProRail_object_detection_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zptv-h2khtwH",
        "colab_type": "text"
      },
      "source": [
        "# Object detection with the tensorflow object detection API\n",
        "In this notebook we will train an object detection algorithm using the tensorflow object detection API.\n",
        "Note that most of the object detection API still does not function with `tensorflow==2.*` or eager execution.\n",
        "\n",
        "This notebook is all about getting it to work. So we ask you to fill in the gaps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtSuWstLkbGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install tf-slim\n",
        "!pip install tensorflow-gpu==1.15.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aygk-HuQ7DRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from io import BytesIO\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image\n",
        "import pylab\n",
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import urllib\n",
        "\n",
        "print(tf.__version__)\n",
        "# tf.enable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foOoVxTslGMO",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Install API\n",
        "Installing the tensorflow object detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ7dTHw_hZjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# Install protoc\n",
        "!wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip -q\n",
        "!unzip -o protobuf.zip\n",
        "!rm protobuf.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsmY3ccEh6s6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "#Clone TensorFlow Object Detection API v1.12.0\n",
        "%mkdir /content/tensorflow\n",
        "%cd /content/tensorflow\n",
        "!rm -fr models\n",
        "!git clone --depth 1 https://github.com/tensorflow/models.git\n",
        "!rm -fr models/.git\n",
        "    \n",
        "# compile ProtoBuffers\n",
        "%cd models/research\n",
        "!/content/bin/protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HTmZCvKiXq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set environment variables\n",
        "os.environ['AUTOGRAPH_VERBOSITY'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONPATH']=f\"{os.environ['PYTHONPATH']}:/content/tensorflow/models/research:/content/tensorflow/models/research/slim\"\n",
        "sys.path.append(\"/content/tensorflow/models/research\")\n",
        "sys.path.append(\"/content/tensorflow/models/research/slim\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVlbRPXrjFZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!python /content/tensorflow/models/research/object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeWzclNLsulS",
        "colab_type": "text"
      },
      "source": [
        "## 2. Prepare data\n",
        "More information about how to create the tfrecord files can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/using_your_own_dataset.md). It can be a a bit tedious, so we provide a script called `generate_tfrecord.py`.\n",
        "\n",
        "The data gets split into separate sets for training, validation and testing. The model learns from the training data, but we use separate validation and test sets to make sure our model generalizes to unseen data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKnnXEA-sxp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Vantage-AI/prorail_railway_fasteners/raw/master/dataset.zip\n",
        "!unzip -o dataset.zip -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f1jZN6Z6daq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create tf record files with a custom script called \"generate_tfrecord\"\n",
        "for split in ['train', 'val', 'test']:\n",
        "  os.environ['SPLIT'] = split\n",
        "  !python /content/dataset/generate_tfrecord.py\\\n",
        "    --csv_input /content/dataset/${SPLIT}_annotations.csv\\\n",
        "    --output_path /content/dataset/${SPLIT}.record\\\n",
        "    --path_to_labels /content/dataset/labelmap.pbtxt\\\n",
        "    --img_path /content/dataset/${SPLIT}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsVqu1qkbBN1",
        "colab_type": "text"
      },
      "source": [
        "## 3. Building a model\n",
        "We will use a COCO pretrained model first, i.e. *Transfer Learning*. \n",
        "* [Here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md) is how to edit the config file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwAB6v_jbCvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "model_name = \"ssd_mobilenet_v2_coco_2018_03_29\"\n",
        "os.environ['MODEL'] = model_name\n",
        "!mkdir models\n",
        "!wget -O ${MODEL}.tar.gz  http://download.tensorflow.org/models/object_detection/${MODEL}.tar.gz -q\n",
        "!tar -C /content/models -xvzf ${MODEL}.tar.gz\n",
        "!rm ${MODEL}.tar.gz\n",
        "\n",
        "# download category index\n",
        "!wget -O models/mscoco_label_map.pbtxt https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n",
        "category_index_coco = label_map_util.create_category_index_from_labelmap(\"models/mscoco_label_map.pbtxt\", use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSX1gUg8et_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://i.pinimg.com/474x/4c/e8/04/4ce8048a99b43441dd58e91b4c3eadcb--choo-tractors.jpg\"\n",
        "data = BytesIO(urllib.request.urlopen(url).read())\n",
        "image = pylab.imread(data, format='jpg').astype(np.uint8)\n",
        "Image.fromarray(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG8oYk7ReCOg",
        "colab_type": "text"
      },
      "source": [
        "Next, we will make a prediction. Lets see if the pretrained model can detect a sheep...?<sup>1</sup>.\n",
        "\n",
        "<sub><sup><sup>1</sup>Since this we are running this in Graph mode (because we do everything in one notebook, you could run these cells in eager mode) it will be a bit tedious...</sup></sub>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FbAfJV2gMDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a prediction\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  new_model = tf.keras.models.load_model(os.path.join(\"/content/models\", \n",
        "                                                      model_name, \n",
        "                                                      \"saved_model\"))\n",
        "  new_model = new_model.signatures['serving_default']\n",
        "  output_dict = new_model(tf.convert_to_tensor(np.expand_dims(image, 0)))  # here we make the prediction\n",
        "  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "g.finalize()\n",
        "\n",
        "# Create session and initialize.\n",
        "session = tf.Session(graph=g)\n",
        "session.run(init_op)\n",
        "output_dict = session.run(output_dict)  # here we execute the graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqVn3Rubery0",
        "colab_type": "text"
      },
      "source": [
        "Next, we visualize the bounding box. Note that this tool will actually draw the box onto the array... so if you want to save it, make a copy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM8Dvy9YpyyY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "  image,\n",
        "  np.array(output_dict['detection_boxes'])[0],\n",
        "  np.array(output_dict['detection_classes']).astype('int')[0],\n",
        "  np.array(output_dict['detection_scores'])[0],\n",
        "  category_index_coco,\n",
        "  use_normalized_coordinates=True,\n",
        "  line_thickness=3)\n",
        "\n",
        "display(Image.fromarray(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ME61RzK1t8m",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train your own model\n",
        "Using pre-trained models is fun, but maybe you want to build your own model. Lets see how we can do just that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTRbwO0ehhCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEEd_BbrQSxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps=30\n",
        "os.environ[\"PIPELINE_CONFIG_PATH\"]=\"/content/dataset/pipeline.config\"\n",
        "os.environ[\"MODEL_DIR\"]=f\"/content/models/my_model\"\n",
        "os.environ[\"NUM_TRAIN_STEPS\"]=f\"{steps}\"  # 1000 steps takes about 10 minutes on a GPU and gives OK results for lightest mobilenet (ssd_mobilenet_v2)\n",
        "os.environ[\"SAMPLE_1_OF_N_EVAL_EXAMPLES\"]=\"1\"\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/models/my_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63fv-DuT1uln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_dir: where the new model will be saved\n",
        "# Make sure this is different from your starting point!\n",
        "%%capture\n",
        "t1 = time.time()\n",
        "!python tensorflow/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\n",
        "    --model_dir=${MODEL_DIR} \\\n",
        "    --num_train_steps=${NUM_TRAIN_STEPS} \\\n",
        "    --sample_1_of_n_eval_examples=${SAMPLE_1_OF_N_EVAL_EXAMPLES} \\\n",
        "    --alsologtostderr\n",
        "t2 = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKbH03BSfI_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Takes about \n",
        "print(f\"{t2 - t1:.1f}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vq9lQDyG8ZX",
        "colab_type": "text"
      },
      "source": [
        "## 5. Export your model for inference\n",
        "This model has to be exported for inference, see [this link](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/exporting_models.md)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDlmkh47JpgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "export_dir=f\"/content/models/my_model_inference\"\n",
        "os.environ['INPUT_TYPE']=\"image_tensor\"\n",
        "os.environ[\"TRAINED_CKPT_PREFIX\"]=os.path.join(os.environ[\"MODEL_DIR\"], f\"model.ckpt-{steps}\")  # extract with\n",
        "os.environ['EXPORT_DIR']=export_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CbPUeRK-HWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!python tensorflow/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=${INPUT_TYPE} \\\n",
        "    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \\\n",
        "    --trained_checkpoint_prefix=${TRAINED_CKPT_PREFIX} \\\n",
        "    --output_directory=${EXPORT_DIR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZu2es09Yofs",
        "colab_type": "text"
      },
      "source": [
        "## 6. Inference\n",
        "Now the fun part... Will it work??? Next, make some predictions on the the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERw6RDwKK7J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(\"/content/models\"):\n",
        "  os.makedirs(\"/content/models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_rhXu37jb7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "image = pylab.imread(\"/content/dataset/test/11003.jpg\", format='jpg').astype(np.uint8)\n",
        "f = plt.figure(figsize=(8, 8))\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fh0xuDqbp27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  new_model = tf.keras.models.load_model(os.path.join(export_dir, \"saved_model\"))\n",
        "  new_model = new_model.signatures['serving_default']\n",
        "  output_dict = new_model(tf.convert_to_tensor(np.expand_dims(image, 0)))\n",
        "  init_op = tf.group([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "g.finalize()\n",
        "\n",
        "# Create session and initialize.\n",
        "session = tf.Session(graph=g)\n",
        "session.run(init_op)\n",
        "output_dict = session.run(output_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArtUm0zqc4Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load labels (this is some sort of a protobuf file)\n",
        "category_index = label_map_util.create_category_index_from_labelmap(\"dataset/labelmap.pbtxt\", use_display_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8s7wyFkcXyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_with_box = image.copy()\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "  image_with_box,\n",
        "  np.array(output_dict['detection_boxes'])[0],\n",
        "  np.array(output_dict['detection_classes']).astype('int')[0],\n",
        "  np.array(output_dict['detection_scores'])[0],\n",
        "  category_index,\n",
        "  use_normalized_coordinates=True,\n",
        "  line_thickness=3)\n",
        "\n",
        "f = plt.figure(figsize=(8, 8))\n",
        "plt.imshow(image_with_box)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-wrYHJbdSXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !zip my_model_inference_precomputed.zip -r /content/models/my_model_inference/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kVc5TNtdRDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boxes = output_dict['detection_boxes']\n",
        "i=0\n",
        "height, width = image.shape[:2]\n",
        "ymin = int(boxes[0,i,0] * height)\n",
        "xmin = int(boxes[0,i,1] * width)\n",
        "ymax = int(boxes[0,i,2] * height)\n",
        "xmax = int(boxes[0,i,3] * width)\n",
        "cropped_image = tf.image.crop_to_bounding_box(image, ymin, xmin, \n",
        "                                       ymax - ymin, xmax - xmin)\n",
        "\n",
        "sess = tf.Session()\n",
        "with sess.as_default():\n",
        "  cropped_image = tf.image.crop_to_bounding_box(image, ymin, xmin, \n",
        "                                       ymax - ymin, xmax - xmin).eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG87UEqeMdrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image.fromarray(cropped_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-SblwuOVvn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}